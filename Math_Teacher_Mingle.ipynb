{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "mDNCb1zIZkte",
        "o2AGb9DcWbKq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "195f1d1d08d44d98be53de7a5993a091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b17bce0ef75641d6af0449ca84bd795a",
              "IPY_MODEL_52b5818e882c44b2aec56eab3521f02e",
              "IPY_MODEL_3af087691a0a471f979b85b2830c620a"
            ],
            "layout": "IPY_MODEL_8f71fee0a99c40868a272332cf338b79"
          }
        },
        "b17bce0ef75641d6af0449ca84bd795a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f63679a8ae4f769a22dace9294f429",
            "placeholder": "​",
            "style": "IPY_MODEL_861287f491244b079d48aad90a3b178a",
            "value": "model.safetensors: 100%"
          }
        },
        "52b5818e882c44b2aec56eab3521f02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e034330faebb4f8cae727662cabb9798",
            "max": 2224765107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d7aafd3d8704d58901dd96b159fd290",
            "value": 2224765107
          }
        },
        "3af087691a0a471f979b85b2830c620a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a016265bbac4f939ecb449c4f0f26e6",
            "placeholder": "​",
            "style": "IPY_MODEL_79df5311e8d0403a8f77afab70bbff53",
            "value": " 2.22G/2.22G [01:30&lt;00:00, 39.6MB/s]"
          }
        },
        "8f71fee0a99c40868a272332cf338b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f63679a8ae4f769a22dace9294f429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861287f491244b079d48aad90a3b178a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e034330faebb4f8cae727662cabb9798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7aafd3d8704d58901dd96b159fd290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a016265bbac4f939ecb449c4f0f26e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79df5311e8d0403a8f77afab70bbff53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ba8c5c11168431eac9f4e08633bf7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9056a784848d45e4854f3a15618fcca4",
              "IPY_MODEL_5a96f5a48b054c5790201ad1a7f117ab",
              "IPY_MODEL_5e60dc5bf47f4f3e8a522dd414ac4e06"
            ],
            "layout": "IPY_MODEL_fa3e7bc4a0014347bea1e0758f639f08"
          }
        },
        "9056a784848d45e4854f3a15618fcca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768a9f26a4264d7387f9597595782406",
            "placeholder": "​",
            "style": "IPY_MODEL_e05274ea45324124b9264fc49a0e6738",
            "value": "generation_config.json: 100%"
          }
        },
        "5a96f5a48b054c5790201ad1a7f117ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987678c09b964aa7b9feacfca341cb87",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_156f53fada944049ac1fa9c60bf88229",
            "value": 190
          }
        },
        "5e60dc5bf47f4f3e8a522dd414ac4e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40acd586e3924ace99fbd900134b7959",
            "placeholder": "​",
            "style": "IPY_MODEL_7bf6234df0654a83874420244e521c6a",
            "value": " 190/190 [00:00&lt;00:00, 2.69kB/s]"
          }
        },
        "fa3e7bc4a0014347bea1e0758f639f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768a9f26a4264d7387f9597595782406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05274ea45324124b9264fc49a0e6738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "987678c09b964aa7b9feacfca341cb87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156f53fada944049ac1fa9c60bf88229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40acd586e3924ace99fbd900134b7959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf6234df0654a83874420244e521c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaeebebb99194177b2c937529213aa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd6273c6e86e407f9bcf57c23e851170",
              "IPY_MODEL_d84dee75d6694f9384c8b13d9ba5275f",
              "IPY_MODEL_fd51ebaf55b14778bbce3bf1c963a659"
            ],
            "layout": "IPY_MODEL_01d002b86c104b87bb9063b608bbe806"
          }
        },
        "fd6273c6e86e407f9bcf57c23e851170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36696270a6a444099ed1a53d69d7f865",
            "placeholder": "​",
            "style": "IPY_MODEL_890af3d4e9ee40dbbe35ce2aee43af7c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d84dee75d6694f9384c8b13d9ba5275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b320382920c8441189d3784427349538",
            "max": 46405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c482beeea0e4845b4528486417b0213",
            "value": 46405
          }
        },
        "fd51ebaf55b14778bbce3bf1c963a659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_928d687b75c747cc95ead7b2e9fe2c9f",
            "placeholder": "​",
            "style": "IPY_MODEL_5d106193b1104c3282bfa40cfcc3d79a",
            "value": " 46.4k/46.4k [00:00&lt;00:00, 587kB/s]"
          }
        },
        "01d002b86c104b87bb9063b608bbe806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36696270a6a444099ed1a53d69d7f865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890af3d4e9ee40dbbe35ce2aee43af7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b320382920c8441189d3784427349538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c482beeea0e4845b4528486417b0213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "928d687b75c747cc95ead7b2e9fe2c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d106193b1104c3282bfa40cfcc3d79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1ffafc016124bc9a611b7a4220e1ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0ff79f9c2664a978d4b8d96e66e999d",
              "IPY_MODEL_4e1b480fcebe4f85a71db5d9fa94a63d",
              "IPY_MODEL_2e8d9a6fdb384a6088ab2139bf003758"
            ],
            "layout": "IPY_MODEL_1c74f12789dc4b09946b4d4c6fd6e944"
          }
        },
        "d0ff79f9c2664a978d4b8d96e66e999d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d839944bacb430285a8b237789570ba",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b1c901e88e4a6ea6a34b61e61ed18f",
            "value": "tokenizer.model: 100%"
          }
        },
        "4e1b480fcebe4f85a71db5d9fa94a63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a773849425c4afdafc60e20f8e05ba1",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46a100f8f7904f3a91bbb820117db044",
            "value": 4241003
          }
        },
        "2e8d9a6fdb384a6088ab2139bf003758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5468aebb3db0493d93d60c7ce78e723c",
            "placeholder": "​",
            "style": "IPY_MODEL_9d0b78564d9e464c8fe5c5c4c88731fd",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 18.8MB/s]"
          }
        },
        "1c74f12789dc4b09946b4d4c6fd6e944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d839944bacb430285a8b237789570ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b1c901e88e4a6ea6a34b61e61ed18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a773849425c4afdafc60e20f8e05ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a100f8f7904f3a91bbb820117db044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5468aebb3db0493d93d60c7ce78e723c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0b78564d9e464c8fe5c5c4c88731fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eff20e598bb34fdea4b912cd431867ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ca48ba8910c4821a8677a766b531e96",
              "IPY_MODEL_6ba7bd275e7849b4be06bd2d5116d4c4",
              "IPY_MODEL_4e081822e129407f9229368c5e07ecba"
            ],
            "layout": "IPY_MODEL_fb1efbc928ba40b1b3e878da148c77bb"
          }
        },
        "3ca48ba8910c4821a8677a766b531e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b8ef736ba3e4d3a99e9b2a596b4a156",
            "placeholder": "​",
            "style": "IPY_MODEL_4cfeb99f83c94f24b7470bade7087b5b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6ba7bd275e7849b4be06bd2d5116d4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eec64138a424f499e6c9ccc5d0548f8",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4649af35c20a4d4192b0bc495e25076b",
            "value": 636
          }
        },
        "4e081822e129407f9229368c5e07ecba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dd9b9b106404082919301e55c03f7b4",
            "placeholder": "​",
            "style": "IPY_MODEL_dbd7f1adf87a4b2eb745b4066daf7702",
            "value": " 636/636 [00:00&lt;00:00, 46.4kB/s]"
          }
        },
        "fb1efbc928ba40b1b3e878da148c77bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8ef736ba3e4d3a99e9b2a596b4a156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cfeb99f83c94f24b7470bade7087b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eec64138a424f499e6c9ccc5d0548f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4649af35c20a4d4192b0bc495e25076b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dd9b9b106404082919301e55c03f7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd7f1adf87a4b2eb745b4066daf7702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925a7464dd494452be558c2077173458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6c8c69bd9e943cfa3d1b8aaa17d0ba8",
              "IPY_MODEL_33fcf3d22fc947139db743c98adb781a",
              "IPY_MODEL_c3d35148a3d34174933828216fa44c89"
            ],
            "layout": "IPY_MODEL_1f27da1c424a49a583e74b8931ae81ff"
          }
        },
        "f6c8c69bd9e943cfa3d1b8aaa17d0ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b38a0a6000a4f61803da745bb9af47f",
            "placeholder": "​",
            "style": "IPY_MODEL_0eaa46b6f46645dfa917eab9a47309dd",
            "value": "tokenizer.json: 100%"
          }
        },
        "33fcf3d22fc947139db743c98adb781a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d5e8124a18a42f19ca5b8b9d88d63e4",
            "max": 17525357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f93b44bd7bf415783f16fdf9b21ad7c",
            "value": 17525357
          }
        },
        "c3d35148a3d34174933828216fa44c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_868eb9ef616b4e2897cb33e3c2ba399a",
            "placeholder": "​",
            "style": "IPY_MODEL_292dbc2597774690a6d20d67a66022ce",
            "value": " 17.5M/17.5M [00:00&lt;00:00, 129MB/s]"
          }
        },
        "1f27da1c424a49a583e74b8931ae81ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b38a0a6000a4f61803da745bb9af47f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eaa46b6f46645dfa917eab9a47309dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d5e8124a18a42f19ca5b8b9d88d63e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f93b44bd7bf415783f16fdf9b21ad7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "868eb9ef616b4e2897cb33e3c2ba399a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292dbc2597774690a6d20d67a66022ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a29403456b584c4bad23206bcf81a1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a4f7bfcb659498e804cb8b233604214",
              "IPY_MODEL_fb50c3a131e142a789c0df0647b53265",
              "IPY_MODEL_ff88bd3b68474330892703825de1b038"
            ],
            "layout": "IPY_MODEL_4ef2db2cf4e0495b945ef1ce5db377d6"
          }
        },
        "2a4f7bfcb659498e804cb8b233604214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1fb63dc30345398d8fcec684458b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_8b8ba7686be145108ce439fa48b6703c",
            "value": "README.md: 100%"
          }
        },
        "fb50c3a131e142a789c0df0647b53265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8916d50bebb34c8cb5df8c3c05cf5ba2",
            "max": 1752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41f1143e0e9a4bc4adff0e8e16541c6f",
            "value": 1752
          }
        },
        "ff88bd3b68474330892703825de1b038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c9b31aac1c4b7a8f2b9758f47480cf",
            "placeholder": "​",
            "style": "IPY_MODEL_dad264744bd3463d9bf8b4621c8789e4",
            "value": " 1.75k/1.75k [00:00&lt;00:00, 111kB/s]"
          }
        },
        "4ef2db2cf4e0495b945ef1ce5db377d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1fb63dc30345398d8fcec684458b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8ba7686be145108ce439fa48b6703c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8916d50bebb34c8cb5df8c3c05cf5ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f1143e0e9a4bc4adff0e8e16541c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8c9b31aac1c4b7a8f2b9758f47480cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad264744bd3463d9bf8b4621c8789e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d81b8845b4e4b6bad3c72d9d5720733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_814f6038c313420db103f9126ee9de4f",
              "IPY_MODEL_ffecf0ec5145489bb0a0335494423b0f",
              "IPY_MODEL_0eec6863e08649b69aa6233952a80983"
            ],
            "layout": "IPY_MODEL_a267322211c348e284f8efbd74716485"
          }
        },
        "814f6038c313420db103f9126ee9de4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f5999076c4497c8fbdb52fbcb3a46b",
            "placeholder": "​",
            "style": "IPY_MODEL_3355508d2cbc45b1a3b5195f30427c36",
            "value": "(…)-00000-of-00001-21df739eb88d711e.parquet: 100%"
          }
        },
        "ffecf0ec5145489bb0a0335494423b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cfa50bf5b674db5b99de39e69e49a09",
            "max": 12856014,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbbc2301a48646959c7d881161553d66",
            "value": 12856014
          }
        },
        "0eec6863e08649b69aa6233952a80983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1465ab2888a446868710ef1bd14b1667",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc61ce429ce4eeeb15ebf98d6fc4f08",
            "value": " 12.9M/12.9M [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "a267322211c348e284f8efbd74716485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f5999076c4497c8fbdb52fbcb3a46b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3355508d2cbc45b1a3b5195f30427c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cfa50bf5b674db5b99de39e69e49a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbbc2301a48646959c7d881161553d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1465ab2888a446868710ef1bd14b1667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc61ce429ce4eeeb15ebf98d6fc4f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "735bfaf120a24c81bbc9e84777f661b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed37005335d241d7a1d560ab9884f159",
              "IPY_MODEL_b7e4e4cddd094364b9a8b8d72210bb94",
              "IPY_MODEL_d4be60ed6959425e9cdd4b003fa2b6ff"
            ],
            "layout": "IPY_MODEL_50d678d0d3244ceba10bc65d4d678a34"
          }
        },
        "ed37005335d241d7a1d560ab9884f159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6e719fcefd34d9eae594bd16c433ee6",
            "placeholder": "​",
            "style": "IPY_MODEL_6828376f6cb741d7bf3df86b5c7e8b36",
            "value": "Generating train split: 100%"
          }
        },
        "b7e4e4cddd094364b9a8b8d72210bb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c4f5840228a42cba6a6ab0c32517ebd",
            "max": 21155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f388a996eb8b41838655101c132a389d",
            "value": 21155
          }
        },
        "d4be60ed6959425e9cdd4b003fa2b6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d4398b17094b48a3ef8c3e50157a09",
            "placeholder": "​",
            "style": "IPY_MODEL_213a1e2c47ce4ab9a4bf724a9acdff05",
            "value": " 21155/21155 [00:00&lt;00:00, 72989.62 examples/s]"
          }
        },
        "50d678d0d3244ceba10bc65d4d678a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6e719fcefd34d9eae594bd16c433ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6828376f6cb741d7bf3df86b5c7e8b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c4f5840228a42cba6a6ab0c32517ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f388a996eb8b41838655101c132a389d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57d4398b17094b48a3ef8c3e50157a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213a1e2c47ce4ab9a4bf724a9acdff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4a025f660e4b57ac4c29ef688b5578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_879a5a4342404abca80a858abb866faa",
              "IPY_MODEL_682ca4958c1c441d84a13ab8dcbe0f2a",
              "IPY_MODEL_f239018527a3439fa1a7675c179593e1"
            ],
            "layout": "IPY_MODEL_14767438b2414ae286f325f8283ae6b2"
          }
        },
        "879a5a4342404abca80a858abb866faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ae730cb481f43359b58988bdce0793b",
            "placeholder": "​",
            "style": "IPY_MODEL_2f6527ea6f7a42cd9a04fb4b34d4b332",
            "value": "README.md: 100%"
          }
        },
        "682ca4958c1c441d84a13ab8dcbe0f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634cdcf0b8464b2180b93d8f191fd129",
            "max": 339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_692fd92c210f4a849b87e8811924eff3",
            "value": 339
          }
        },
        "f239018527a3439fa1a7675c179593e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918cd5c431dd48cd89b6fd8256c5f559",
            "placeholder": "​",
            "style": "IPY_MODEL_12a1b472c6db498c9bce5960a9741a82",
            "value": " 339/339 [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "14767438b2414ae286f325f8283ae6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae730cb481f43359b58988bdce0793b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6527ea6f7a42cd9a04fb4b34d4b332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "634cdcf0b8464b2180b93d8f191fd129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692fd92c210f4a849b87e8811924eff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918cd5c431dd48cd89b6fd8256c5f559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a1b472c6db498c9bce5960a9741a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a79fef88a3e4adda19ed24fdd3dbecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae3a49cb917c4fdea98b8b49fc5cc11d",
              "IPY_MODEL_9c7d0c8c41244602b071241b5ea7a4fe",
              "IPY_MODEL_d38463f6cbce4818b2988befb1bbd583"
            ],
            "layout": "IPY_MODEL_2a2b8ea2fb03411ca82f8767f0986479"
          }
        },
        "ae3a49cb917c4fdea98b8b49fc5cc11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aad4cb51d0674e4d8e515379c786ebe2",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6124c791214d14a81c44527b89c42e",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "9c7d0c8c41244602b071241b5ea7a4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac501899d5c4b64a0969d3ed2ddf006",
            "max": 8946,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d86883acc9ed42688ec649d01a4f5703",
            "value": 8946
          }
        },
        "d38463f6cbce4818b2988befb1bbd583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5dc4d57826495a85a542b92c2dac67",
            "placeholder": "​",
            "style": "IPY_MODEL_88cbb4a30dea4404b0da4794c84cb2e8",
            "value": " 8.95k/8.95k [00:00&lt;00:00, 620kB/s]"
          }
        },
        "2a2b8ea2fb03411ca82f8767f0986479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad4cb51d0674e4d8e515379c786ebe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6124c791214d14a81c44527b89c42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac501899d5c4b64a0969d3ed2ddf006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86883acc9ed42688ec649d01a4f5703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec5dc4d57826495a85a542b92c2dac67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88cbb4a30dea4404b0da4794c84cb2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5418d32de9a4506814acc6b7aa7d0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75159a10269144ed930d434e2d34e057",
              "IPY_MODEL_6a0961872c354f209eff5dff5ae7bc69",
              "IPY_MODEL_f4b191e5a04d4f3ebaa1a527db2ebed6"
            ],
            "layout": "IPY_MODEL_ad8e4880a7fb4ffaafd9cf4ebeb300e4"
          }
        },
        "75159a10269144ed930d434e2d34e057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ac24d14634411087387be87d609fa6",
            "placeholder": "​",
            "style": "IPY_MODEL_7d39b26b1a7049fbb8b14e4a588d3203",
            "value": "Generating train split: 100%"
          }
        },
        "6a0961872c354f209eff5dff5ae7bc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efca0cbcfafd4891b2508f6e7d7d7c98",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b084258253449ca022a599bf76971a",
            "value": 75
          }
        },
        "f4b191e5a04d4f3ebaa1a527db2ebed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ef652bc0ff46c7af1e3b8285d5eb01",
            "placeholder": "​",
            "style": "IPY_MODEL_1c94b8229c7f4d5d9a397a58fc9814cd",
            "value": " 75/75 [00:00&lt;00:00, 2750.19 examples/s]"
          }
        },
        "ad8e4880a7fb4ffaafd9cf4ebeb300e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ac24d14634411087387be87d609fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d39b26b1a7049fbb8b14e4a588d3203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efca0cbcfafd4891b2508f6e7d7d7c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b084258253449ca022a599bf76971a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6ef652bc0ff46c7af1e3b8285d5eb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c94b8229c7f4d5d9a397a58fc9814cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b0992edff845b49155aff1837c5fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc96683fad1a47278e86b1bd6a7a9cb2",
              "IPY_MODEL_3474fdad3acd483aa6a6ec6cb27fc2a7",
              "IPY_MODEL_a05e24a293094195af801f72135adf99"
            ],
            "layout": "IPY_MODEL_e8546951258f436a813aea71afcaa64f"
          }
        },
        "dc96683fad1a47278e86b1bd6a7a9cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fa7d4b2e1f4ea482773373afa600ec",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1db00e3f9d41d59695e453144ee7fe",
            "value": "Map: 100%"
          }
        },
        "3474fdad3acd483aa6a6ec6cb27fc2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f09dc62839624effb9e8ddff7501e3c3",
            "max": 21230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9010db09d644443eb12576a530047d61",
            "value": 21230
          }
        },
        "a05e24a293094195af801f72135adf99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3013a36831e742ce8fe8394af08e604f",
            "placeholder": "​",
            "style": "IPY_MODEL_36ed657ce07643ae811838a2d0e2e5e5",
            "value": " 21230/21230 [00:00&lt;00:00, 37081.29 examples/s]"
          }
        },
        "e8546951258f436a813aea71afcaa64f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fa7d4b2e1f4ea482773373afa600ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1db00e3f9d41d59695e453144ee7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f09dc62839624effb9e8ddff7501e3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9010db09d644443eb12576a530047d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3013a36831e742ce8fe8394af08e604f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ed657ce07643ae811838a2d0e2e5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0d4049d96a246a89cb917a089e7cdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed20302e19314773aa7108cf6e915fbb",
              "IPY_MODEL_a8c1cd8f043b4b13b8c081057590aaa0",
              "IPY_MODEL_df1d7a74416144d7ac24b12cf2515e1d"
            ],
            "layout": "IPY_MODEL_b748351ca4624610a986fa34890eeb37"
          }
        },
        "ed20302e19314773aa7108cf6e915fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_147a82b962664de89e1d348d4f41001b",
            "placeholder": "​",
            "style": "IPY_MODEL_4f6dbaf8f0db486bbca41de1c55a63cd",
            "value": "Map (num_proc=8): 100%"
          }
        },
        "a8c1cd8f043b4b13b8c081057590aaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba17b4a1ea124966892e141f09b4413b",
            "max": 21230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20700f23613440d48a7cfe77ba7328da",
            "value": 21230
          }
        },
        "df1d7a74416144d7ac24b12cf2515e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d409a6240f4fa8b2e39c9c9a9e6f66",
            "placeholder": "​",
            "style": "IPY_MODEL_e4a46aa5fb914040b090e0c059675b7d",
            "value": " 21230/21230 [00:27&lt;00:00, 1324.86 examples/s]"
          }
        },
        "b748351ca4624610a986fa34890eeb37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147a82b962664de89e1d348d4f41001b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6dbaf8f0db486bbca41de1c55a63cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba17b4a1ea124966892e141f09b4413b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20700f23613440d48a7cfe77ba7328da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7d409a6240f4fa8b2e39c9c9a9e6f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a46aa5fb914040b090e0c059675b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d093baaa431547dba6942749382ef880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29a650b86c6b438689854b8731d4d164",
              "IPY_MODEL_98dc65b45cf64ec091007833d6a0b604",
              "IPY_MODEL_336cdfb6bdcc48a682a25659c3df9390"
            ],
            "layout": "IPY_MODEL_b2fb290262144e57ae2ba57fc4581c3a"
          }
        },
        "29a650b86c6b438689854b8731d4d164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613f2b17f4e24093a66057e27ddcb07d",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5f2b733d5e49a595e8004bedceb02f",
            "value": "unsloth.F16.gguf: 100%"
          }
        },
        "98dc65b45cf64ec091007833d6a0b604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0d3994b4dd405e9a95cf1caef404f5",
            "max": 5235213216,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf4e5e9132f94361b2f7a575761936a0",
            "value": 5235213216
          }
        },
        "336cdfb6bdcc48a682a25659c3df9390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caabe3f13a6946a8883cd51929800dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_afd5b8b0749a4b0b9b40253754bdee01",
            "value": " 5.24G/5.24G [02:32&lt;00:00, 43.7MB/s]"
          }
        },
        "b2fb290262144e57ae2ba57fc4581c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613f2b17f4e24093a66057e27ddcb07d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5f2b733d5e49a595e8004bedceb02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f0d3994b4dd405e9a95cf1caef404f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4e5e9132f94361b2f7a575761936a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caabe3f13a6946a8883cd51929800dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd5b8b0749a4b0b9b40253754bdee01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc524ae4a014dd49a48fbd343ff5a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b4c71e4229343edbb36250334af227b",
              "IPY_MODEL_c96253bffc7e4cdcad8701573a2b8217",
              "IPY_MODEL_37d9f5fa662d4af58766e435853ba5b6"
            ],
            "layout": "IPY_MODEL_e1ffc77774dd4d1ebd0e07d2488f0466"
          }
        },
        "4b4c71e4229343edbb36250334af227b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260e3a761053427fbac834064e44a346",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e28c22b91846b18ff3aedf4386dbfb",
            "value": "unsloth.Q4_K_M.gguf: 100%"
          }
        },
        "c96253bffc7e4cdcad8701573a2b8217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd0b70ce430495dbe725fc2dae78551",
            "max": 1708581792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb96d0fa4f0432db8a87d374bea35c8",
            "value": 1708581792
          }
        },
        "37d9f5fa662d4af58766e435853ba5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40bb620af3ff49fb838f5b8036744cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_f5827b18a08d46e09de9e652713d0a1c",
            "value": " 1.71G/1.71G [00:41&lt;00:00, 41.7MB/s]"
          }
        },
        "e1ffc77774dd4d1ebd0e07d2488f0466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260e3a761053427fbac834064e44a346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e28c22b91846b18ff3aedf4386dbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccd0b70ce430495dbe725fc2dae78551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb96d0fa4f0432db8a87d374bea35c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40bb620af3ff49fb838f5b8036744cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5827b18a08d46e09de9e652713d0a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c4308ef3ea54076946b2576b44409af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85ea2616bd184b3282ce6d86fddaf265",
              "IPY_MODEL_90a861e265334ee2a8b4403f1f2ec281",
              "IPY_MODEL_eee2736542064f238c6366122299803a"
            ],
            "layout": "IPY_MODEL_a0edbfbd3264423b94e99de73b83db66"
          }
        },
        "85ea2616bd184b3282ce6d86fddaf265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a641b7e85f6410aae2c5b5866d11e94",
            "placeholder": "​",
            "style": "IPY_MODEL_45d6efd3e1034ae7b85aee5c3737b16d",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "90a861e265334ee2a8b4403f1f2ec281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa4da8a84a449efb1fdccaf03a2f94d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b28958ae01ea4081b2e34cafd4154d91",
            "value": 0
          }
        },
        "eee2736542064f238c6366122299803a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c810f46ede74d948084090df32b98a8",
            "placeholder": "​",
            "style": "IPY_MODEL_25aab17aa98446b1ab5a8e3210769c5d",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "a0edbfbd3264423b94e99de73b83db66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a641b7e85f6410aae2c5b5866d11e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d6efd3e1034ae7b85aee5c3737b16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aa4da8a84a449efb1fdccaf03a2f94d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28958ae01ea4081b2e34cafd4154d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c810f46ede74d948084090df32b98a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25aab17aa98446b1ab5a8e3210769c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ev1025/gemma_sprint/blob/main/Math_Teacher_Mingle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Math Teacher Mingle"
      ],
      "metadata": {
        "id": "kiBZz3_1ADWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#구글 드라이브를 마운트합니다.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/outputs'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEHzI5d_YOmI",
        "outputId": "33625d05-f375-4a0b-a77c-e11fe38d4d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#허깅페이스 설치\n",
        "!pip install datasets huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRkzb5YjV8EB",
        "outputId": "b9fcfd36-9cd0-47c7-fb2d-ea0f2433fadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "#허깅페이스 액세스토큰\n",
        "hf_token = \"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\"\n",
        "\n",
        "# 허깅페이스 로그인\n",
        "login(hf_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf5wglnuV-3g",
        "outputId": "bafe730a-9412-499f-a983-ee17ca86f1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치"
      ],
      "metadata": {
        "id": "_NU7LjfUANq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Unsloth 설치\n",
        "\n",
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "\n",
        "# We have to check which Torch version for Xformers (2.3 -> 0.0.27)\n",
        "from torch import __version__; from packaging.version import Version as V\n",
        "xformers = \"xformers==0.0.27\" if V(__version__) < V(\"2.4.0\") else \"xformers\"\n",
        "!pip install --no-deps {xformers} trl peft accelerate bitsandbytes triton"
      ],
      "metadata": {
        "id": "wBmxrB4N_LOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 세팅"
      ],
      "metadata": {
        "id": "N0-8mr1rAPqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Model(사전 훈련된 모델)\n"
      ],
      "metadata": {
        "id": "EhXNN8IPAU51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # 모델이 입력으로 받을 수 있는 최대 입력 시퀀스 (길면 더 많은 메모리 소모)\n",
        "dtype = torch.float16 # None 자동 / torch.float16(gpu- Teslcolab-newa T4, V100,) / Bfloat16 (gpu - Ampere+,A100, RTX 30xx 이상)\n",
        "load_in_4bit = True   # 양자화(메모리 사용량 축소를 위해 쪼개기)\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-2-2b-bnb-4bit\", # 모델 선택\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,                # 양자화(PEFT모델 init_lora_weights='loftq'와 중복불가능)\n",
        "    token = hf_token\n",
        ")"
      ],
      "metadata": {
        "id": "RJZnT1xwALw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "195f1d1d08d44d98be53de7a5993a091",
            "b17bce0ef75641d6af0449ca84bd795a",
            "52b5818e882c44b2aec56eab3521f02e",
            "3af087691a0a471f979b85b2830c620a",
            "8f71fee0a99c40868a272332cf338b79",
            "36f63679a8ae4f769a22dace9294f429",
            "861287f491244b079d48aad90a3b178a",
            "e034330faebb4f8cae727662cabb9798",
            "7d7aafd3d8704d58901dd96b159fd290",
            "0a016265bbac4f939ecb449c4f0f26e6",
            "79df5311e8d0403a8f77afab70bbff53",
            "5ba8c5c11168431eac9f4e08633bf7b1",
            "9056a784848d45e4854f3a15618fcca4",
            "5a96f5a48b054c5790201ad1a7f117ab",
            "5e60dc5bf47f4f3e8a522dd414ac4e06",
            "fa3e7bc4a0014347bea1e0758f639f08",
            "768a9f26a4264d7387f9597595782406",
            "e05274ea45324124b9264fc49a0e6738",
            "987678c09b964aa7b9feacfca341cb87",
            "156f53fada944049ac1fa9c60bf88229",
            "40acd586e3924ace99fbd900134b7959",
            "7bf6234df0654a83874420244e521c6a",
            "aaeebebb99194177b2c937529213aa9f",
            "fd6273c6e86e407f9bcf57c23e851170",
            "d84dee75d6694f9384c8b13d9ba5275f",
            "fd51ebaf55b14778bbce3bf1c963a659",
            "01d002b86c104b87bb9063b608bbe806",
            "36696270a6a444099ed1a53d69d7f865",
            "890af3d4e9ee40dbbe35ce2aee43af7c",
            "b320382920c8441189d3784427349538",
            "8c482beeea0e4845b4528486417b0213",
            "928d687b75c747cc95ead7b2e9fe2c9f",
            "5d106193b1104c3282bfa40cfcc3d79a",
            "c1ffafc016124bc9a611b7a4220e1ff6",
            "d0ff79f9c2664a978d4b8d96e66e999d",
            "4e1b480fcebe4f85a71db5d9fa94a63d",
            "2e8d9a6fdb384a6088ab2139bf003758",
            "1c74f12789dc4b09946b4d4c6fd6e944",
            "3d839944bacb430285a8b237789570ba",
            "b2b1c901e88e4a6ea6a34b61e61ed18f",
            "6a773849425c4afdafc60e20f8e05ba1",
            "46a100f8f7904f3a91bbb820117db044",
            "5468aebb3db0493d93d60c7ce78e723c",
            "9d0b78564d9e464c8fe5c5c4c88731fd",
            "eff20e598bb34fdea4b912cd431867ae",
            "3ca48ba8910c4821a8677a766b531e96",
            "6ba7bd275e7849b4be06bd2d5116d4c4",
            "4e081822e129407f9229368c5e07ecba",
            "fb1efbc928ba40b1b3e878da148c77bb",
            "1b8ef736ba3e4d3a99e9b2a596b4a156",
            "4cfeb99f83c94f24b7470bade7087b5b",
            "2eec64138a424f499e6c9ccc5d0548f8",
            "4649af35c20a4d4192b0bc495e25076b",
            "9dd9b9b106404082919301e55c03f7b4",
            "dbd7f1adf87a4b2eb745b4066daf7702",
            "925a7464dd494452be558c2077173458",
            "f6c8c69bd9e943cfa3d1b8aaa17d0ba8",
            "33fcf3d22fc947139db743c98adb781a",
            "c3d35148a3d34174933828216fa44c89",
            "1f27da1c424a49a583e74b8931ae81ff",
            "4b38a0a6000a4f61803da745bb9af47f",
            "0eaa46b6f46645dfa917eab9a47309dd",
            "9d5e8124a18a42f19ca5b8b9d88d63e4",
            "9f93b44bd7bf415783f16fdf9b21ad7c",
            "868eb9ef616b4e2897cb33e3c2ba399a",
            "292dbc2597774690a6d20d67a66022ce"
          ]
        },
        "outputId": "bb1c7b13-ed4c-4500-d7af-3f0aa783f70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.8: Fast Gemma2 patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "195f1d1d08d44d98be53de7a5993a091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ba8c5c11168431eac9f4e08633bf7b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaeebebb99194177b2c937529213aa9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ffafc016124bc9a611b7a4220e1ff6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eff20e598bb34fdea4b912cd431867ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "925a7464dd494452be558c2077173458"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PEFT Model(모델의 미세 파라미터 조정)"
      ],
      "metadata": {
        "id": "KrB1AQ7HAfGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,            # LoRA의 랭크 값, 메모리사용량 증가, 모델의 표현력 좋아짐 (8, 16, 32, 64, 128), 메모리 영향 있음\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",\"embed_tokens\",],\n",
        "                      # \"embed_tokens\", \"lm_head\",], # 포함하면 파라미터 수 폭증, 메모리 영향 있음\n",
        "    lora_alpha = 32,  # Lora의 스케일링, 학습성능 개선될 수 있음, r의 2배수로 하는 게 좋음 메모리 영향 있음\n",
        "    lora_dropout = 0, # 과적합 방지, 0이 최적화\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # \"unsloth\"나 True로 설정하면 긴 컨텍스트 처리시 메모리 30% 절약, 메모리 영향 있음\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,       # 안정화된 랭크를 사용할지\n",
        "    loftq_config = None,     # 로라 양자화 안함(하고싶으면 아래 init_lora 켜기, ), 메모리 영향 있음\n",
        "    # init_lora_weights='loftq'# 양자화로 모델의 메모리 사용량 줄이고 추론 속도를 빠르게 함(Pretrained모델의 load_in_4bit와 중복 안 됨)\n",
        ")"
      ],
      "metadata": {
        "id": "Jg0O2CMtASNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fafaca84-9cd0-48ab-a3c4-c77ae39c915b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Offloading input_embeddings to disk to save VRAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/unsloth/models/_utils.py:866: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  offloaded_W = torch.load(filename, map_location = \"cpu\", mmap = True)\n",
            "Unsloth 2024.8 patched 26 layers with 26 QKV layers, 26 O layers and 26 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Casting embed_tokens to float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로라 파라미터 몇% 학습됐는지(trainable%:)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "Bjh74aqVEFvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7328ede-2adb-4fb0-855b-e0e3e6077555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 610,590,720 || all params: 3,814,756,608 || trainable%: 16.0060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 세팅"
      ],
      "metadata": {
        "id": "DRe_ByfDAyP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 세부 데이터 업로드(Fine tuning data upload)"
      ],
      "metadata": {
        "id": "mDNCb1zIZkte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# math_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/math_data.csv')"
      ],
      "metadata": {
        "id": "IgnfnQWDVKwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# math_data.head()"
      ],
      "metadata": {
        "id": "F9pBGrggaLVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # from datasets import Dataset\n",
        "# # 열 이름 변경: input -> instruction, response -> out\n",
        "# math_data = math_data.rename(columns={'input': 'instruction', 'response': 'output'})\n",
        "\n",
        "# # pandas DataFrame을 Dataset으로 변환\n",
        "# math_data_prep = Dataset.from_pandas(math_data)\n",
        "# math_data_prep = math_data_prep.add_column(\"url\", [\"\"] * len(math_data_prep)) # alphako 형식맞추기 위해 url열 추가\n",
        "\n",
        "# # 변환된 데이터셋 확인\n",
        "# print(math_data_prep)"
      ],
      "metadata": {
        "id": "8zNzjb83XFJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #hugging face에 수학 데이터 업로드\n",
        "# math_data_prep.push_to_hub(\"Envy1025/mathdata\")"
      ],
      "metadata": {
        "id": "2gVHWqLsZ3_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기"
      ],
      "metadata": {
        "id": "tG81v_KKA-l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "alpaca_dataset = load_dataset(\"beomi/KoAlpaca-v1.1a\",  split = \"train\") # \"train[10%]\" 이렇게 쓰면 데이터 10%만 가져옴\n",
        "math_dataset = load_dataset(\"Envy1025/mathdata\",  split = \"train\")\n",
        "\n",
        "# CPT를 위해 두 데이터 MERGE\n",
        "dataset = concatenate_datasets([alpaca_dataset,math_dataset])\n",
        "print(dataset)\n",
        "\n",
        "# alpaca_dataset = alpaca_dataset.train_test_split(train_size=0.01)[\"train\"] 너무 많으면 1%데이터만"
      ],
      "metadata": {
        "id": "VUcQ1PK-A64J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "a29403456b584c4bad23206bcf81a1bc",
            "2a4f7bfcb659498e804cb8b233604214",
            "fb50c3a131e142a789c0df0647b53265",
            "ff88bd3b68474330892703825de1b038",
            "4ef2db2cf4e0495b945ef1ce5db377d6",
            "7e1fb63dc30345398d8fcec684458b2b",
            "8b8ba7686be145108ce439fa48b6703c",
            "8916d50bebb34c8cb5df8c3c05cf5ba2",
            "41f1143e0e9a4bc4adff0e8e16541c6f",
            "f8c9b31aac1c4b7a8f2b9758f47480cf",
            "dad264744bd3463d9bf8b4621c8789e4",
            "1d81b8845b4e4b6bad3c72d9d5720733",
            "814f6038c313420db103f9126ee9de4f",
            "ffecf0ec5145489bb0a0335494423b0f",
            "0eec6863e08649b69aa6233952a80983",
            "a267322211c348e284f8efbd74716485",
            "92f5999076c4497c8fbdb52fbcb3a46b",
            "3355508d2cbc45b1a3b5195f30427c36",
            "5cfa50bf5b674db5b99de39e69e49a09",
            "cbbc2301a48646959c7d881161553d66",
            "1465ab2888a446868710ef1bd14b1667",
            "6dc61ce429ce4eeeb15ebf98d6fc4f08",
            "735bfaf120a24c81bbc9e84777f661b7",
            "ed37005335d241d7a1d560ab9884f159",
            "b7e4e4cddd094364b9a8b8d72210bb94",
            "d4be60ed6959425e9cdd4b003fa2b6ff",
            "50d678d0d3244ceba10bc65d4d678a34",
            "c6e719fcefd34d9eae594bd16c433ee6",
            "6828376f6cb741d7bf3df86b5c7e8b36",
            "9c4f5840228a42cba6a6ab0c32517ebd",
            "f388a996eb8b41838655101c132a389d",
            "57d4398b17094b48a3ef8c3e50157a09",
            "213a1e2c47ce4ab9a4bf724a9acdff05",
            "ea4a025f660e4b57ac4c29ef688b5578",
            "879a5a4342404abca80a858abb866faa",
            "682ca4958c1c441d84a13ab8dcbe0f2a",
            "f239018527a3439fa1a7675c179593e1",
            "14767438b2414ae286f325f8283ae6b2",
            "4ae730cb481f43359b58988bdce0793b",
            "2f6527ea6f7a42cd9a04fb4b34d4b332",
            "634cdcf0b8464b2180b93d8f191fd129",
            "692fd92c210f4a849b87e8811924eff3",
            "918cd5c431dd48cd89b6fd8256c5f559",
            "12a1b472c6db498c9bce5960a9741a82",
            "3a79fef88a3e4adda19ed24fdd3dbecb",
            "ae3a49cb917c4fdea98b8b49fc5cc11d",
            "9c7d0c8c41244602b071241b5ea7a4fe",
            "d38463f6cbce4818b2988befb1bbd583",
            "2a2b8ea2fb03411ca82f8767f0986479",
            "aad4cb51d0674e4d8e515379c786ebe2",
            "5c6124c791214d14a81c44527b89c42e",
            "8ac501899d5c4b64a0969d3ed2ddf006",
            "d86883acc9ed42688ec649d01a4f5703",
            "ec5dc4d57826495a85a542b92c2dac67",
            "88cbb4a30dea4404b0da4794c84cb2e8",
            "a5418d32de9a4506814acc6b7aa7d0d0",
            "75159a10269144ed930d434e2d34e057",
            "6a0961872c354f209eff5dff5ae7bc69",
            "f4b191e5a04d4f3ebaa1a527db2ebed6",
            "ad8e4880a7fb4ffaafd9cf4ebeb300e4",
            "22ac24d14634411087387be87d609fa6",
            "7d39b26b1a7049fbb8b14e4a588d3203",
            "efca0cbcfafd4891b2508f6e7d7d7c98",
            "b7b084258253449ca022a599bf76971a",
            "f6ef652bc0ff46c7af1e3b8285d5eb01",
            "1c94b8229c7f4d5d9a397a58fc9814cd"
          ]
        },
        "outputId": "eb0eb014-77b3-45be-e590-bf5534559847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.75k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a29403456b584c4bad23206bcf81a1bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-21df739eb88d711e.parquet:   0%|          | 0.00/12.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d81b8845b4e4b6bad3c72d9d5720733"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/21155 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "735bfaf120a24c81bbc9e84777f661b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/339 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea4a025f660e4b57ac4c29ef688b5578"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/8.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a79fef88a3e4adda19ed24fdd3dbecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/75 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5418d32de9a4506814acc6b7aa7d0d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['instruction', 'output', 'url'],\n",
            "    num_rows: 21230\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]['output']"
      ],
      "metadata": {
        "id": "YSs_E6dnhLQB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "db7ee0fc-1bf3-48ec-8fa5-e0f40301500d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'양파는 잎이 아닌 식물의 줄기 부분입니다. 고구마는 식물의 뿌리 부분입니다. \\n\\n식물의 부위의 구분에 대해 궁금해하는 분이라면 분명 이 질문에 대한 답을 찾고 있을 것입니다. 양파는 잎이 아닌 줄기 부분입니다. 고구마는 다른 질문과 답변에서 언급된 것과 같이 뿌리 부분입니다. 따라서, 양파는 식물의 줄기 부분이 되고, 고구마는 식물의 뿌리 부분입니다.\\n\\n 덧붙이는 답변: 고구마 줄기도 볶아먹을 수 있나요? \\n\\n고구마 줄기도 식용으로 볶아먹을 수 있습니다. 하지만 줄기 뿐만 아니라, 잎, 씨, 뿌리까지 모든 부위가 식용으로 활용되기도 합니다. 다만, 한국에서는 일반적으로 뿌리 부분인 고구마를 주로 먹습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 프롬프트 형식"
      ],
      "metadata": {
        "id": "AelrQ_FcA3LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### output:\n",
        "{}\"\"\"\n",
        "# Becomes:\n",
        "alpaca_prompt = \"\"\"다음은 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성하세요.\n",
        "\n",
        "### 지침:\n",
        "{}\n",
        "\n",
        "### 응답:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # output의 끝을 알리는 토큰\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    texts = []\n",
        "    for instruction, output in zip(examples['instruction'], examples['output']):\n",
        "            text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
        "            texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass"
      ],
      "metadata": {
        "id": "z34mqvaMAeo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 → 프롬프트"
      ],
      "metadata": {
        "id": "HlL9bTfZEuTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 형태를 프롬프트 형태로 변경\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "id": "eu5ENAzYEtlk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f8b0992edff845b49155aff1837c5fe9",
            "dc96683fad1a47278e86b1bd6a7a9cb2",
            "3474fdad3acd483aa6a6ec6cb27fc2a7",
            "a05e24a293094195af801f72135adf99",
            "e8546951258f436a813aea71afcaa64f",
            "63fa7d4b2e1f4ea482773373afa600ec",
            "9f1db00e3f9d41d59695e453144ee7fe",
            "f09dc62839624effb9e8ddff7501e3c3",
            "9010db09d644443eb12576a530047d61",
            "3013a36831e742ce8fe8394af08e604f",
            "36ed657ce07643ae811838a2d0e2e5e5"
          ]
        },
        "outputId": "aa04c0da-2e4d-474a-a8e6-0ab31140ef9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21230 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8b0992edff845b49155aff1837c5fe9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련"
      ],
      "metadata": {
        "id": "1PiywdAHCt9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continued Pre-Training(CPT)"
      ],
      "metadata": {
        "id": "d53DUlENDFce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/transformers/v4.2.2/main_classes/optimizer_schedules.html#transformers.SchedulerType"
      ],
      "metadata": {
        "id": "LaV6tpLYxqWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
        "\n",
        "trainer = UnslothTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length, # 최대 시퀀스 길이\n",
        "    dataset_num_proc = 8, # 데이터 처리에 사용할 프로세스\n",
        "    packing=False,        # 짧은 시퀀스에 대한 학습 속도를 5배 빠르게 할 수 있음\n",
        "\n",
        "    args = UnslothTrainingArguments(\n",
        "        per_device_train_batch_size = 2, # 각 디바이스 훈련 배치 크기 / 메모리 영향 있음\n",
        "        gradient_accumulation_steps = 8, # 메모리 영향 있음\n",
        "        max_steps = 120,         # epoch와 비슷한거\n",
        "        # warmup_steps = 10,     # 수행할 워밍업 단계 수\n",
        "        # warmup_ratio = 0.1,    # 학습률 최적화 파라미터(0.1 = 초반 10%는 점진적으로 학습률 상승하다가 90%는 일정하게 상승)\n",
        "        # num_train_epochs = 1,  # 훈련 반복 수\n",
        "\n",
        "        # Select a 2 to 10x smaller learning rate for the embedding matrices!\n",
        "        learning_rate = 5e-5,           # fine tuning 학습률\n",
        "        embedding_learning_rate = 1e-5, # pretrain과 fine tuning 사이의 학습에 대한 학습률\n",
        "\n",
        "        fp16 = True, #  not is_bfloat16_supported() / 메모리 영향 있음\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\", # 최적화 알고리즘\n",
        "        weight_decay = 0.00,  # 가중치 감소\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "JgJD9OrHCs8L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b0d4049d96a246a89cb917a089e7cdd6",
            "ed20302e19314773aa7108cf6e915fbb",
            "a8c1cd8f043b4b13b8c081057590aaa0",
            "df1d7a74416144d7ac24b12cf2515e1d",
            "b748351ca4624610a986fa34890eeb37",
            "147a82b962664de89e1d348d4f41001b",
            "4f6dbaf8f0db486bbca41de1c55a63cd",
            "ba17b4a1ea124966892e141f09b4413b",
            "20700f23613440d48a7cfe77ba7328da",
            "e7d409a6240f4fa8b2e39c9c9a9e6f66",
            "e4a46aa5fb914040b090e0c059675b7d"
          ]
        },
        "outputId": "e8efa120-d246-420b-822f-93ed0731c85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=8):   0%|          | 0/21230 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0d4049d96a246a89cb917a089e7cdd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SFT모델"
      ],
      "metadata": {
        "id": "o2AGb9DcWbKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments\n",
        "# from unsloth import is_bfloat16_supported\n",
        "\n",
        "# # 파인튜닝을 위한 트레이너 셋팅\n",
        "# trainer = SFTTrainer(\n",
        "#     model = model,\n",
        "#     tokenizer = tokenizer,          # 변환용 토크나이저\n",
        "#     train_dataset = alpaca_dataset,\n",
        "#     dataset_text_field = \"text\",    # 데이터셋에서 텍스트필드 이름\n",
        "#     max_seq_length = max_seq_length,# 최대 토큰수\n",
        "#     dataset_num_proc = 2,           # 전처리 프로세스 수\n",
        "#     packing = False,                # 동시 처리용 - 현재 쓸모 없음\n",
        "#     # 트레이닝 인자\n",
        "#     args = TrainingArguments(\n",
        "#         per_device_train_batch_size = 2, # 각 디바이스당 훈련 배치 크기\n",
        "#         gradient_accumulation_steps = 4, # 그라디언트 누적 단계 (learning_rate / warmup_steps) * step = 현재 스탭의 학습률(초기 학습률을 낮게 설정.)\n",
        "#         warmup_steps = 5,     # 웜업 스탭 수\n",
        "#         # num_train_epochs = 3, # 데이터셋을 몇번 학습할건지 epoch\n",
        "#         max_steps = 30,      # 최대 몇 스탭까지 공부할 것인가?\n",
        "#         logging_steps = 1,    # 몇 스탭마다 기록할지.\n",
        "#         learning_rate = 2e-4, # 학습률\n",
        "#         fp16 = None,         # fp16 사용 여부, bf16이 지원되지 않는 경우에만 사용 is_bfloat16_supported()\n",
        "#         bf16= torch.cuda.is_bf16_supported(),# bf16 사용 여부, bf16이 지원되는 경우에만 사용\n",
        "#         optim = \"adamw_8bit\",                # 최적화 알고리즘\n",
        "#         weight_decay = 0.01,                 # 가중치 감소\n",
        "#         lr_scheduler_type = \"linear\",        # 학습률 스케줄러 유형 \"cosine\"도 있음\n",
        "#         seed = 3407,                         # 랜덤시드임\n",
        "#         output_dir = output_dir,             # 저장위치\n",
        "#     ),\n",
        "# )"
      ],
      "metadata": {
        "id": "zO2LN85qWIgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습"
      ],
      "metadata": {
        "id": "FqkDC0jGDIqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파인튜닝 시작\n",
        "import os\n",
        "\n",
        "# 학습 체크포인트 폴더 유무를 체크합니다.\n",
        "if not os.path.exists(output_dir):\n",
        "    trainer_stats = trainer.train(resume_from_checkpoint = True)\n",
        "else:\n",
        "    trainer_stats = trainer.train() # 모델을 훈련시키고 통계를 반환"
      ],
      "metadata": {
        "id": "3DX8Mp0ZdFL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fe13ca2-f807-4164-9090-43a04a9f3411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 21,230 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 8\n",
            "\\        /    Total batch size = 16 | Total steps = 120\n",
            " \"-____-\"     Number of trainable parameters = 610,590,720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Setting lr = 1.00e-05 instead of 5.00e-05 for embed_tokens.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 16:45, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.122900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.179500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.883100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.927100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.799500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.773300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.689200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.654200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.777600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.723300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.744400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.622800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.756000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.717800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.774600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.641100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.655300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.599900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.642800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.767200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.879400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.857500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.672300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.679200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.662400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.590100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.698700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.726700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.702500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.632900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.634800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.617600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.649900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.621700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.583300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.671600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.615900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.621800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.788700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.678600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.548100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.706800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.768900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.561600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.696500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.682200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.654200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.678000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.681500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.694900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.765400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.700700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.704900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.660500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.834600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.647600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.745400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.599000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.610400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.731500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.656200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.601400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.666800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.714300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.729800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.802600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.583400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.676600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.857600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.687600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.570700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.760100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.685100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.700600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.667200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.632800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.644600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.741100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.725500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.700400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.743600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.638700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.561100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.700900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.613700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.729100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.616100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>1.572100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>1.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.788400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>1.739300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.651600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>1.602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.584800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.646000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>1.581600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>1.649400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>1.510500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>1.675900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>1.569000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.669700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 테스트"
      ],
      "metadata": {
        "id": "e0qahpH7Dbk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        # \"Continue the fibonacci sequence: 1, 1, 2, 3, 5, 8,\", # instruction\n",
        "        \"피보나치 수열을 계속하세요: 1, 1, 2, 3, 5, 8,\", # instruction\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "NygjuXhlDOSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0006a013-3f86-4a59-869f-33cb4d4b9a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>다음은 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성하세요.\\n\\n### 지침:\\n피보나치 수열을 계속하세요: 1, 1, 2, 3, 5, 8,\\n\\n### 응답:\\n피보나치 수열은 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        # \"What is Korean music like?\"\n",
        "        \"거듭제곱이 무엇인가요?\", # instruction\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ],
      "metadata": {
        "id": "o5T7HM7WE6oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67708cbb-e22e-4334-b709-de4623612b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos>다음은 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성하세요.\n",
            "\n",
            "### 지침:\n",
            "거듭제곱이 무엇인가요?\n",
            "\n",
            "### 응답:\n",
            "거듭제곱은 숫자를 곱해도 곱해도 같은 결과를 얻을 수 있는 방법입니다. 예를 들어, 2^3 = 8, 2^4 = 16, 2^5 = 32, 2^6 = 64, 2^7 = 128, 2^8 = 256, 2^9 = 512, 2^10 = 1024, 2^11 = 2048, 2^12 = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        # \"What is Korean music like?\"\n",
        "        \"최소공배수가 무엇인가요?\", # instruction\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ],
      "metadata": {
        "id": "SaMBf_1pkNAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 저장"
      ],
      "metadata": {
        "id": "5noJOzlrIBCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 허깅페이스 레포지토리용 파라미터\n",
        "# base_model = \"unsloth/gemma-2-9b-bnb-4bit\" # pretrained 모델,\n",
        "# huggingface_repo = \"Envy1025/gemma2test\" # 업로드할 레포지토리\n",
        "# save_method = (\n",
        "#     \"merged_16bit\"  # \"merged_4bit\", \"merged_4bit_forced\", \"merged_16bit\", \"lora\" 저장방식\n",
        "# )"
      ],
      "metadata": {
        "id": "zme4dzr-ICgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 로컬에 저장하기\n",
        "# model.save_pretrained_merged(\n",
        "#     base_model,\n",
        "#     tokenizer,\n",
        "#     save_method=save_method,  # 저장 방식을 16비트 병합으로 설정\n",
        "# )"
      ],
      "metadata": {
        "id": "fwnfKc-ZIDgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hub 에 업로드하기(허깅페이스) - 명시적으로 base_model 입력하지 않아도 내부에서 알아서 지정됨\n",
        "# model.push_to_hub_merged(\n",
        "#     huggingface_repo, # 허깅페이스 레포지토리이름\n",
        "#     tokenizer,\n",
        "#     save_method=save_method, # lora 저장방식\n",
        "#     token=hf_token, # 허깅페이스 토큰\n",
        "# )"
      ],
      "metadata": {
        "id": "rKoNc8goIFsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GGUF\n"
      ],
      "metadata": {
        "id": "OriOsaPMIcDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GGUF 파일은 LLM (Large Language Models) 및 AI 모델과 관련된 압축된 모델 형식 중 하나입니다. GGUF는 주로 효율적인 모델 저장 및 배포를 위해 사용\n",
        "\n"
      ],
      "metadata": {
        "id": "Ox5OJ6usIhR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "양자화 https://github.com/unslothai/unsloth/wiki#gguf-quantization-options"
      ],
      "metadata": {
        "id": "jTvCo4gdIjaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로컬(구글드라이브) 저장\n",
        "# gguf 파라미터4비트 모델이므로 이 방식이 적합\n",
        "quantization_method = \"q4_k_m\"   # \"q8_0\"  \"f16\" \"q8_0\" \"q4_k_m\" \"q5_k_m\"\n",
        "model.save_pretrained_gguf(\n",
        "    \"./content/drive/MyDrive/outputs\",\n",
        "    tokenizer=tokenizer,\n",
        "    quantization_method=quantization_method,\n",
        ")"
      ],
      "metadata": {
        "id": "s_HBGc2KIn4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cff5ec-6c72-4f3e-bff1-a0142bd5aca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 2.2G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 5.42 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:01<00:00, 13.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving ./content/drive/MyDrive/outputs/pytorch_model-00001-of-00002.bin...\n",
            "Unsloth: Saving ./content/drive/MyDrive/outputs/pytorch_model-00002-of-00002.bin...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting gemma2 model. Can use fast conversion = False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at ./content/drive/MyDrive/outputs into f16 GGUF format.\n",
            "The output location will be ././content/drive/MyDrive/outputs/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: outputs\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,                 torch.float16 --> F16, shape = {2304, 256000}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:output_norm.weight,                torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 2\n",
            "INFO:gguf.vocab:Setting special token type eos to 1\n",
            "INFO:gguf.vocab:Setting special token type unk to 3\n",
            "INFO:gguf.vocab:Setting special token type pad to 0\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:content/drive/MyDrive/outputs/unsloth.F16.gguf: n_tensors = 288, total_size = 5.2G\n",
            "Writing: 100%|██████████| 5.23G/5.23G [00:48<00:00, 107Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to content/drive/MyDrive/outputs/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: ././content/drive/MyDrive/outputs/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3755 (822b6322)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '././content/drive/MyDrive/outputs/unsloth.F16.gguf' to '././content/drive/MyDrive/outputs/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 288 tensors from ././content/drive/MyDrive/outputs/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = gemma-2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
            "llama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\n",
            "llama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\n",
            "llama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\n",
            "llama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\n",
            "llama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  16:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
            "llama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\n",
            "llama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  31:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  105 tensors\n",
            "llama_model_loader: - type  f16:  183 tensors\n",
            "[   1/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =    f16, converting to q6_K .. size =  1125.00 MiB ->   461.43 MiB\n",
            "[   2/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[   3/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[   4/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[   5/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[   6/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[   7/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[   8/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[   9/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  10/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  11/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  12/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  13/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  14/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  15/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  16/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  17/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  18/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  19/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  20/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  21/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  22/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  23/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  24/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  25/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  26/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  27/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  28/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  29/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  30/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  31/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  32/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  33/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  34/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  35/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  36/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  37/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  38/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  39/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  40/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  41/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  42/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  43/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  44/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  45/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  46/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  47/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  48/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  49/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  50/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  51/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  52/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  53/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  54/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  55/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  56/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  57/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  58/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  59/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  60/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  61/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  62/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  63/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  64/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  65/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  66/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  67/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  68/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  69/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  70/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  71/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  72/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  73/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  74/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  75/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  76/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  77/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  78/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  79/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  80/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  81/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  82/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  83/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  84/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  85/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  86/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  87/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  88/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  89/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  90/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  91/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  92/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  93/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  94/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  95/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  96/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  97/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  98/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  99/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 100/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 101/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 102/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 103/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 104/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 105/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 106/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 107/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 108/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 109/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 110/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 111/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 112/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 113/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 114/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 115/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 116/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 117/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 118/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 119/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 120/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 121/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 122/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 123/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 124/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 125/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 126/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 127/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 128/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 129/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 130/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 131/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 132/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 133/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 134/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 135/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 136/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 137/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 138/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 139/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 140/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 141/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 142/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 143/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 144/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 145/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 146/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 147/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 148/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 149/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 150/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 151/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 152/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 153/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 154/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 155/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 156/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 157/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 158/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 159/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 160/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 161/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 162/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 163/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 164/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 165/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 166/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 167/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 168/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 169/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 170/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 171/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 172/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 173/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 174/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 175/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 176/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 177/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 178/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 179/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 180/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 181/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 182/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 183/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 184/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 185/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 186/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 187/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 188/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 189/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 190/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 191/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 192/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 193/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 194/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 195/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 196/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 197/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 198/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 199/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 200/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 201/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 202/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 203/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 204/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 205/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 206/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 207/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 208/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 209/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 210/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 211/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 212/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 213/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 214/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 215/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 216/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 217/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 218/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 219/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 220/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 221/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 222/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 223/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 224/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 225/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 226/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 227/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 228/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 229/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 230/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 231/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 232/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 233/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 234/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 235/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 236/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 237/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 238/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 239/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 240/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 241/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 242/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 243/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 244/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 245/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 246/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 247/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 248/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 249/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 250/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 251/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 252/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 253/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 254/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 255/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 256/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 257/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 258/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 259/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 260/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 261/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 262/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 263/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 264/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 265/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 266/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 267/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 268/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 269/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 270/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 271/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 273/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 274/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 275/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 276/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 277/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 278/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 279/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 280/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 281/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 282/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 283/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 284/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 285/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 286/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 287/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 288/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "llama_model_quantize_internal: model size  =  4986.92 MB\n",
            "llama_model_quantize_internal: quant size  =  1623.67 MB\n",
            "\n",
            "main: quantize time = 269817.34 ms\n",
            "main:    total time = 269817.34 ms\n",
            "Unsloth: Conversion completed! Output location: ././content/drive/MyDrive/outputs/unsloth.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hub 에 GGUF 업로드\n",
        "model.push_to_hub_gguf(\n",
        "    \"Envy1025/math_teachear_mingle\",\n",
        "    tokenizer,\n",
        "    quantization_method=quantization_method,\n",
        "    token=hf_token,\n",
        ")"
      ],
      "metadata": {
        "id": "k6rGnnh8Ipfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d093baaa431547dba6942749382ef880",
            "29a650b86c6b438689854b8731d4d164",
            "98dc65b45cf64ec091007833d6a0b604",
            "336cdfb6bdcc48a682a25659c3df9390",
            "b2fb290262144e57ae2ba57fc4581c3a",
            "613f2b17f4e24093a66057e27ddcb07d",
            "ce5f2b733d5e49a595e8004bedceb02f",
            "9f0d3994b4dd405e9a95cf1caef404f5",
            "bf4e5e9132f94361b2f7a575761936a0",
            "caabe3f13a6946a8883cd51929800dc9",
            "afd5b8b0749a4b0b9b40253754bdee01",
            "7dc524ae4a014dd49a48fbd343ff5a1b",
            "4b4c71e4229343edbb36250334af227b",
            "c96253bffc7e4cdcad8701573a2b8217",
            "37d9f5fa662d4af58766e435853ba5b6",
            "e1ffc77774dd4d1ebd0e07d2488f0466",
            "260e3a761053427fbac834064e44a346",
            "a2e28c22b91846b18ff3aedf4386dbfb",
            "ccd0b70ce430495dbe725fc2dae78551",
            "7eb96d0fa4f0432db8a87d374bea35c8",
            "40bb620af3ff49fb838f5b8036744cf9",
            "f5827b18a08d46e09de9e652713d0a1c"
          ]
        },
        "outputId": "aa47c13f-5e67-4b34-f815-ee6204a8f20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 6.51 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:00<00:00, 36.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving Envy1025/math_teachear_mingle/pytorch_model-00001-of-00002.bin...\n",
            "Unsloth: Saving Envy1025/math_teachear_mingle/pytorch_model-00002-of-00002.bin...\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at Envy1025/math_teachear_mingle into f16 GGUF format.\n",
            "The output location will be ./Envy1025/math_teachear_mingle/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: math_teachear_mingle\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,                 torch.float16 --> F16, shape = {2304, 256000}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:output_norm.weight,                torch.float16 --> F32, shape = {2304}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 2\n",
            "INFO:gguf.vocab:Setting special token type eos to 1\n",
            "INFO:gguf.vocab:Setting special token type unk to 3\n",
            "INFO:gguf.vocab:Setting special token type pad to 0\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:Envy1025/math_teachear_mingle/unsloth.F16.gguf: n_tensors = 288, total_size = 5.2G\n",
            "Writing: 100%|██████████| 5.23G/5.23G [00:54<00:00, 95.2Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to Envy1025/math_teachear_mingle/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: ./Envy1025/math_teachear_mingle/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3755 (822b6322)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing './Envy1025/math_teachear_mingle/unsloth.F16.gguf' to './Envy1025/math_teachear_mingle/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 288 tensors from ./Envy1025/math_teachear_mingle/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = gemma-2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
            "llama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\n",
            "llama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\n",
            "llama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\n",
            "llama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\n",
            "llama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  16:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
            "llama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\n",
            "llama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  31:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  105 tensors\n",
            "llama_model_loader: - type  f16:  183 tensors\n",
            "[   1/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =    f16, converting to q6_K .. size =  1125.00 MiB ->   461.43 MiB\n",
            "[   2/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[   3/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[   4/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[   5/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[   6/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[   7/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[   8/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[   9/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  10/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  11/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  12/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  13/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  14/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  15/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  16/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  17/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  18/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  19/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  20/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  21/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  22/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  23/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  24/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  25/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  26/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  27/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  28/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  29/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  30/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  31/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  32/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  33/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  34/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  35/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  36/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  37/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  38/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  39/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  40/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  41/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  42/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  43/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  44/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  45/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  46/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  47/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  48/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  49/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  50/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  51/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  52/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  53/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  54/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  55/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  56/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  57/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  58/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  59/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  60/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  61/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  62/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  63/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  64/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  65/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  66/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  67/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  68/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  69/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  70/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  71/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  72/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  73/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  74/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  75/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  76/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  77/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  78/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  79/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  80/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  81/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  82/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  83/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  84/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  85/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  86/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  87/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  88/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  89/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  90/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  91/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[  92/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[  93/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[  94/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  95/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[  96/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[  97/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  98/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[  99/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 100/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 101/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 102/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 103/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 104/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 105/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 106/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 107/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 108/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 109/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 110/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 111/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 112/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 113/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 114/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 115/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 116/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 117/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 118/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 119/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 120/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 121/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 122/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 123/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 124/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 125/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 126/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 127/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 128/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 129/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 130/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 131/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 132/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 133/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 134/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 135/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 136/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 137/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 138/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 139/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 140/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 141/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 142/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 143/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 144/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 145/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 146/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 147/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 148/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 149/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 150/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 151/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 152/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 153/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 154/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 155/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 156/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 157/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 158/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 159/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 160/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 161/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 162/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 163/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 164/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 165/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 166/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 167/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 168/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 169/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 170/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 171/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 172/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 173/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 174/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 175/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 176/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 177/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 178/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 179/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 180/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 181/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 182/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 183/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 184/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 185/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 186/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 187/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 188/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 189/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 190/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 191/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 192/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 193/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 194/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 195/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 196/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 197/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 198/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 199/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 200/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 201/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 202/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 203/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 204/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 205/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 206/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 207/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 208/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 209/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 210/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 211/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 212/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 213/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 214/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 215/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 216/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 217/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 218/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 219/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 220/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 221/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 222/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 223/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 224/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 225/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 226/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 227/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 228/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 229/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 230/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 231/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 232/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 233/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 234/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 235/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 236/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 237/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 238/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 239/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 240/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 241/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 242/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 243/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 244/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 245/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 246/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 247/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 248/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 249/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 250/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 251/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 252/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 253/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 254/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 255/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 256/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 257/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 258/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 259/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 260/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 261/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 262/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 263/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 264/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 265/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 266/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 267/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 268/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 269/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 270/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 271/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 273/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 274/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 275/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 276/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 277/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 278/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
            "[ 279/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
            "[ 280/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
            "[ 281/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 282/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
            "[ 283/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
            "[ 284/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 285/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 286/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 287/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "[ 288/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
            "llama_model_quantize_internal: model size  =  4986.92 MB\n",
            "llama_model_quantize_internal: quant size  =  1623.67 MB\n",
            "\n",
            "main: quantize time = 274039.29 ms\n",
            "main:    total time = 274039.29 ms\n",
            "Unsloth: Conversion completed! Output location: ./Envy1025/math_teachear_mingle/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.F16.gguf:   0%|          | 0.00/5.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d093baaa431547dba6942749382ef880"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/Envy1025/math_teachear_mingle\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc524ae4a014dd49a48fbd343ff5a1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/Envy1025/math_teachear_mingle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gradio로 실행해보기"
      ],
      "metadata": {
        "id": "AYpFDUXiIvtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 재 시작 필요\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "nPGE5G2oIwp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba9824c-7203-4484-f2d9-5c44436c66b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.114.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.6)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.114.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.114.2 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.5 semantic-version-2.10.0 starlette-0.38.5 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Hugging Face 모델 설정\n",
        "model_name = \"Envy1025/math_teachear_mingle\"\n",
        "\n",
        "# Hugging Face 토큰 입력\n",
        "login(token=\"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\")\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=True)\n",
        "\n",
        "def generate_text(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs[\"input_ids\"], max_length=150)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Gradio 인터페이스 설정\n",
        "interface = gr.Interface(fn=generate_text, inputs=\"text\", outputs=\"text\", title=\"Math Teacher Mingle\")\n",
        "\n",
        "# Gradio 앱 실행\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "pWod7XBrIzuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "0c4308ef3ea54076946b2576b44409af",
            "85ea2616bd184b3282ce6d86fddaf265",
            "90a861e265334ee2a8b4403f1f2ec281",
            "eee2736542064f238c6366122299803a",
            "a0edbfbd3264423b94e99de73b83db66",
            "5a641b7e85f6410aae2c5b5866d11e94",
            "45d6efd3e1034ae7b85aee5c3737b16d",
            "0aa4da8a84a449efb1fdccaf03a2f94d",
            "b28958ae01ea4081b2e34cafd4154d91",
            "4c810f46ede74d948084090df32b98a8",
            "25aab17aa98446b1ab5a8e3210769c5d"
          ]
        },
        "outputId": "6567c8c7-c992-4f95-d413-3daa15c06b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c4308ef3ea54076946b2576b44409af"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### chainlit 으로 실행해보기(코랩방법 못찾음)"
      ],
      "metadata": {
        "id": "8-PlpxB5IrTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.chainlit.io/integrations/langchain"
      ],
      "metadata": {
        "id": "wqV4cJJi3a4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install chainlit transformers\n",
        "!pip install langchain langchain_community\n",
        "!pip install chainlit\n"
      ],
      "metadata": {
        "id": "0siMFRyLIsax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import Runnable\n",
        "from langchain.schema.runnable.config import RunnableConfig\n",
        "\n",
        "import chainlit as cl\n",
        "\n",
        "\n",
        "@cl.on_chat_start\n",
        "async def on_chat_start():\n",
        "    model = ChatOpenAI(streaming=True)\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You're a very knowledgeable historian who provides accurate and eloquent answers to historical questions.\",\n",
        "            ),\n",
        "            (\"human\", \"{question}\"),\n",
        "        ]\n",
        "    )\n",
        "    runnable = prompt | model | StrOutputParser()\n",
        "    cl.user_session.set(\"runnable\", runnable)\n",
        "\n",
        "\n",
        "@cl.on_message\n",
        "async def on_message(message: cl.Message):\n",
        "    runnable = cl.user_session.get(\"runnable\")  # type: Runnable\n",
        "\n",
        "    msg = cl.Message(content=\"\")\n",
        "\n",
        "    async for chunk in runnable.astream(\n",
        "        {\"question\": message.content},\n",
        "        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),\n",
        "    ):\n",
        "        await msg.stream_token(chunk)\n",
        "\n",
        "    await msg.send()"
      ],
      "metadata": {
        "id": "xleach971rL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chainlit run app.py -w"
      ],
      "metadata": {
        "id": "nUHMCZuH12ub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
